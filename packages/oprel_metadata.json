{
  "name": "oprel",
  "version": "0.2.0",
  "summary": "Run LLMs locally with one line of Python. Ollama alternative with server mode, conversation memory, and 50+ model aliases. The SQLite of AI.",
  "author": "Ragul",
  "license": "MIT",
  "home_page": "https://github.com/ragultv/oprel-SDK",
  "download_filename": "oprel-0.2.0.tar.gz",
  "download_time": "2026-01-25T13:52:43.493490",
  "package_url": "https://pypi.org/project/oprel/"
}